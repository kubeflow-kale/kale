{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57bc647d-1b15-4251-a865-e4e65d002eb4",
   "metadata": {},
   "source": [
    "# ML Pipeline Test\n",
    "\n",
    "This notebook demonstrates a complete machine learning pipeline that will be converted to Kubeflow Pipelines using the Pipeline Builder extension.\n",
    "\n",
    "We'll build a simple iris classification model with the following steps:\n",
    "1. Data loading and exploration\n",
    "2. Data preprocessing \n",
    "3. Model training\n",
    "4. Model evaluation\n",
    "5. Results summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea83a553-1062-4139-ba08-38c1f08d5201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-2.3.0-cp313-cp313-win_amd64.whl.metadata (19 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Downloading numpy-2.3.0-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\programs\\miniconda\\envs\\kale-ext\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\programs\\miniconda\\envs\\kale-ext\\lib\\site-packages (from pandas) (2025.2)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in d:\\programs\\miniconda\\envs\\kale-ext\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Using cached pandas-2.3.0-cp313-cp313-win_amd64.whl (11.0 MB)\n",
      "Downloading numpy-2.3.0-cp313-cp313-win_amd64.whl (12.7 MB)\n",
      "   ---------------------------------------- 0.0/12.7 MB ? eta -:--:--\n",
      "   ---------------------- ----------------- 7.1/12.7 MB 52.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.7/12.7 MB 47.7 MB/s eta 0:00:00\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: tzdata, numpy, pandas\n",
      "\n",
      "   ---------------------------------------- 0/3 [tzdata]\n",
      "   ---------------------------------------- 0/3 [tzdata]\n",
      "   ---------------------------------------- 0/3 [tzdata]\n",
      "   ---------------------------------------- 0/3 [tzdata]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [numpy]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   ---------------------------------------- 3/3 [pandas]\n",
      "\n",
      "Successfully installed numpy-2.3.0 pandas-2.3.0 tzdata-2025.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c30e637e-95ab-4252-8be3-875bb6e87c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.7.0-cp313-cp313-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in d:\\programs\\miniconda\\envs\\kale-ext\\lib\\site-packages (from scikit-learn) (2.3.0)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\n",
      "  Using cached scipy-1.15.3-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached scikit_learn-1.7.0-cp313-cp313-win_amd64.whl (10.7 MB)\n",
      "Using cached joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Using cached scipy-1.15.3-cp313-cp313-win_amd64.whl (41.0 MB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ---------------------------------------- 4/4 [scikit-learn]\n",
      "\n",
      "Successfully installed joblib-1.5.1 scikit-learn-1.7.0 scipy-1.15.3 threadpoolctl-3.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eea8c82e-8e54-462c-a9a8-32576283103e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.10.3-cp313-cp313-win_amd64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.2-cp313-cp313-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.58.4-cp313-cp313-win_amd64.whl.metadata (108 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.8-cp313-cp313-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in d:\\programs\\miniconda\\envs\\kale-ext\\lib\\site-packages (from matplotlib) (2.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\programs\\miniconda\\envs\\kale-ext\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Using cached pillow-11.2.1-cp313-cp313-win_amd64.whl.metadata (9.1 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\programs\\miniconda\\envs\\kale-ext\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\programs\\miniconda\\envs\\kale-ext\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Using cached matplotlib-3.10.3-cp313-cp313-win_amd64.whl (8.1 MB)\n",
      "Using cached contourpy-1.3.2-cp313-cp313-win_amd64.whl (223 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.58.4-cp313-cp313-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.2/2.2 MB 21.1 MB/s eta 0:00:00\n",
      "Using cached kiwisolver-1.4.8-cp313-cp313-win_amd64.whl (71 kB)\n",
      "Using cached pillow-11.2.1-cp313-cp313-win_amd64.whl (2.7 MB)\n",
      "Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "\n",
      "   ---------------------------------------- 0/7 [pyparsing]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ---------------------------- ----------- 5/7 [contourpy]\n",
      "   ---------------------------- ----------- 5/7 [contourpy]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------------- 7/7 [matplotlib]\n",
      "\n",
      "Successfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.58.4 kiwisolver-1.4.8 matplotlib-3.10.3 pillow-11.2.1 pyparsing-3.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76a54994-06ce-4408-b6e1-2bf6fb8db15d",
   "metadata": {
    "tags": [
     "step:data-loading"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loading iris dataset...\n",
      " Dataset loaded successfully!\n",
      " Dataset shape: (150, 6)\n",
      " Features: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      " Target classes: ['setosa' 'versicolor' 'virginica']\n",
      "\n",
      " Dataset Overview:\n",
      "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
      "count         150.000000        150.000000         150.000000   \n",
      "mean            5.843333          3.057333           3.758000   \n",
      "std             0.828066          0.435866           1.765298   \n",
      "min             4.300000          2.000000           1.000000   \n",
      "25%             5.100000          2.800000           1.600000   \n",
      "50%             5.800000          3.000000           4.350000   \n",
      "75%             6.400000          3.300000           5.100000   \n",
      "max             7.900000          4.400000           6.900000   \n",
      "\n",
      "       petal width (cm)      target  \n",
      "count        150.000000  150.000000  \n",
      "mean           1.199333    1.000000  \n",
      "std            0.762238    0.819232  \n",
      "min            0.100000    0.000000  \n",
      "25%            0.300000    0.000000  \n",
      "50%            1.300000    1.000000  \n",
      "75%            1.800000    2.000000  \n",
      "max            2.500000    2.000000  \n",
      "\n",
      " Summary: 150 samples, 4 features, 3 classes\n"
     ]
    }
   ],
   "source": [
    "# Data Loading and Initial Exploration\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the iris dataset\n",
    "print(\" Loading iris dataset...\")\n",
    "iris = load_iris()\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "df['target_name'] = df['target'].map({0: 'setosa', 1: 'versicolor', 2: 'virginica'})\n",
    "\n",
    "print(f\" Dataset loaded successfully!\")\n",
    "print(f\" Dataset shape: {df.shape}\")\n",
    "print(f\" Features: {list(df.columns[:-2])}\")\n",
    "print(f\" Target classes: {df['target_name'].unique()}\")\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\n Dataset Overview:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Save some key metrics\n",
    "total_samples = len(df)\n",
    "num_features = len(iris.feature_names)\n",
    "num_classes = len(iris.target_names)\n",
    "\n",
    "print(f\"\\n Summary: {total_samples} samples, {num_features} features, {num_classes} classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a69f9127-235b-4700-9f8c-86d8d8782c2e",
   "metadata": {
    "tags": [
     "step:preprocessing"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Starting data preprocessing...\n",
      " Features shape: (150, 4)\n",
      " Target shape: (150,)\n",
      " Training set: 120 samples\n",
      " Test set: 30 samples\n",
      " Feature scaling completed\n",
      " Missing values: 0\n",
      " Preprocessing completed successfully!\n",
      " Scaled features - Mean: [-0. -0.  0.  0.]\n",
      " Scaled features - Std: [1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing and Feature Engineering\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "print(\" Starting data preprocessing...\")\n",
    "\n",
    "# Prepare features and target\n",
    "X = df.drop(['target', 'target_name'], axis=1)\n",
    "y = df['target']\n",
    "\n",
    "print(f\" Features shape: {X.shape}\")\n",
    "print(f\" Target shape: {y.shape}\")\n",
    "\n",
    "# Split the data\n",
    "test_size = 0.2\n",
    "random_state = 42\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    ")\n",
    "\n",
    "print(f\" Training set: {X_train.shape[0]} samples\")\n",
    "print(f\" Test set: {X_test.shape[0]} samples\")\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\" Feature scaling completed\")\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = df.isnull().sum().sum()\n",
    "print(f\" Missing values: {missing_values}\")\n",
    "\n",
    "# Feature statistics after scaling\n",
    "train_mean = np.mean(X_train_scaled, axis=0)\n",
    "train_std = np.std(X_train_scaled, axis=0)\n",
    "\n",
    "print(\" Preprocessing completed successfully!\")\n",
    "print(f\" Scaled features - Mean: {train_mean.round(3)}\")\n",
    "print(f\" Scaled features - Std: {train_std.round(3)}\")\n",
    "\n",
    "preprocessing_summary = {\n",
    "    'train_samples': len(X_train),\n",
    "    'test_samples': len(X_test),\n",
    "    'features': X_train.shape[1],\n",
    "    'test_size_ratio': test_size\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2762d54a-70ce-4e7a-899c-88b02f4a20cb",
   "metadata": {
    "tags": [
     "step:training"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Starting model training...\n",
      " Training Random Forest...\n",
      "    Training time: 0.159s\n",
      " Training Logistic Regression...\n",
      "    Training time: 0.019s\n",
      " Training SVM...\n",
      "    Training time: 0.003s\n",
      " All models trained successfully!\n",
      " Trained 3 models: ['RandomForest', 'LogisticRegression', 'SVM']\n",
      " RandomForest training accuracy: 1.0000\n",
      " LogisticRegression training accuracy: 0.9583\n",
      " SVM training accuracy: 0.9750\n",
      " Best training accuracy: RandomForest (1.0000)\n"
     ]
    }
   ],
   "source": [
    "# Model Training\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "print(\" Starting model training...\")\n",
    "\n",
    "# Define model parameters\n",
    "rf_params = {\n",
    "    'n_estimators': 100,\n",
    "    'random_state': 42,\n",
    "    'max_depth': 5\n",
    "}\n",
    "\n",
    "lr_params = {\n",
    "    'random_state': 42,\n",
    "    'max_iter': 1000\n",
    "}\n",
    "\n",
    "svm_params = {\n",
    "    'random_state': 42,\n",
    "    'kernel': 'rbf'\n",
    "}\n",
    "\n",
    "# Train multiple models\n",
    "models = {}\n",
    "training_times = {}\n",
    "\n",
    "print(\" Training Random Forest...\")\n",
    "start_time = time.time()\n",
    "rf_model = RandomForestClassifier(**rf_params)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "training_times['RandomForest'] = time.time() - start_time\n",
    "models['RandomForest'] = rf_model\n",
    "print(f\"    Training time: {training_times['RandomForest']:.3f}s\")\n",
    "\n",
    "print(\" Training Logistic Regression...\")\n",
    "start_time = time.time()\n",
    "lr_model = LogisticRegression(**lr_params)\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "training_times['LogisticRegression'] = time.time() - start_time\n",
    "models['LogisticRegression'] = lr_model\n",
    "print(f\"    Training time: {training_times['LogisticRegression']:.3f}s\")\n",
    "\n",
    "print(\" Training SVM...\")\n",
    "start_time = time.time()\n",
    "svm_model = SVC(**svm_params)\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "training_times['SVM'] = time.time() - start_time\n",
    "models['SVM'] = svm_model\n",
    "print(f\"    Training time: {training_times['SVM']:.3f}s\")\n",
    "\n",
    "print(\" All models trained successfully!\")\n",
    "print(f\" Trained {len(models)} models: {list(models.keys())}\")\n",
    "\n",
    "# Quick training accuracy check\n",
    "train_accuracies = {}\n",
    "for name, model in models.items():\n",
    "    train_pred = model.predict(X_train_scaled)\n",
    "    train_acc = accuracy_score(y_train, train_pred)\n",
    "    train_accuracies[name] = train_acc\n",
    "    print(f\" {name} training accuracy: {train_acc:.4f}\")\n",
    "\n",
    "best_train_model = max(train_accuracies, key=train_accuracies.get)\n",
    "print(f\" Best training accuracy: {best_train_model} ({train_accuracies[best_train_model]:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7008f5c5-20f9-4716-8f7f-4b19ea6acff1",
   "metadata": {
    "tags": [
     "step:evaluation"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Starting model evaluation...\n",
      "\n",
      " Evaluating RandomForest...\n",
      "    Accuracy: 0.9333\n",
      "    Precision: 0.9333\n",
      "    Recall: 0.9333\n",
      "    F1-Score: 0.9333\n",
      "\n",
      " Evaluating LogisticRegression...\n",
      "    Accuracy: 0.9333\n",
      "    Precision: 0.9333\n",
      "    Recall: 0.9333\n",
      "    F1-Score: 0.9333\n",
      "\n",
      " Evaluating SVM...\n",
      "    Accuracy: 0.9667\n",
      "    Precision: 0.9697\n",
      "    Recall: 0.9667\n",
      "    F1-Score: 0.9666\n",
      "\n",
      " Best Model: SVM\n",
      " Best Accuracy: 0.9667\n",
      "\n",
      " Detailed Classification Report for SVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       1.00      0.90      0.95        10\n",
      "   virginica       0.91      1.00      0.95        10\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.97      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n",
      "\n",
      " Confusion Matrix for SVM:\n",
      "[[10  0  0]\n",
      " [ 0  9  1]\n",
      " [ 0  0 10]]\n",
      "\n",
      " Model Comparison Summary:\n",
      "RandomForest    | Acc: 0.9333 | Time: 0.159s\n",
      "LogisticRegression | Acc: 0.9333 | Time: 0.019s\n",
      "SVM             | Acc: 0.9667 | Time: 0.003s\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation and Performance Analysis\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "print(\" Starting model evaluation...\")\n",
    "\n",
    "# Evaluate all models\n",
    "evaluation_results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n Evaluating {name}...\")\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    # Store results\n",
    "    evaluation_results[name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'training_time': training_times[name]\n",
    "    }\n",
    "    \n",
    "    print(f\"    Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"    Precision: {precision:.4f}\")\n",
    "    print(f\"    Recall: {recall:.4f}\")\n",
    "    print(f\"    F1-Score: {f1:.4f}\")\n",
    "\n",
    "# Find best model\n",
    "best_model_name = max(evaluation_results, key=lambda x: evaluation_results[x]['accuracy'])\n",
    "best_model = models[best_model_name]\n",
    "best_accuracy = evaluation_results[best_model_name]['accuracy']\n",
    "\n",
    "print(f\"\\n Best Model: {best_model_name}\")\n",
    "print(f\" Best Accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "# Detailed evaluation of best model\n",
    "print(f\"\\n Detailed Classification Report for {best_model_name}:\")\n",
    "y_pred_best = best_model.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred_best, target_names=iris.target_names))\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_best)\n",
    "print(f\"\\n Confusion Matrix for {best_model_name}:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Model comparison summary\n",
    "print(f\"\\n Model Comparison Summary:\")\n",
    "for name, results in evaluation_results.items():\n",
    "    print(f\"{name:15} | Acc: {results['accuracy']:.4f} | Time: {results['training_time']:.3f}s\")\n",
    "\n",
    "# Final metrics for pipeline output\n",
    "final_accuracy = best_accuracy\n",
    "final_model_name = best_model_name\n",
    "total_models_trained = len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1d20140-daaf-4514-9960-aa915a74d5a0",
   "metadata": {
    "tags": [
     "pipeline-parameters"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Setting up pipeline parameters...\n",
      " Pipeline parameters configured:\n",
      "    Dataset: iris\n",
      "    Target: target\n",
      "    Test size: 0.2\n",
      "    Random state: 42\n",
      "    Version: 1.0.0\n"
     ]
    }
   ],
   "source": [
    "# Pipeline Configuration Parameters\n",
    "print(\" Setting up pipeline parameters...\")\n",
    "\n",
    "# Data parameters\n",
    "dataset_name = \"iris\"\n",
    "target_column = \"target\"\n",
    "test_size_param = 0.2\n",
    "random_state_param = 42\n",
    "\n",
    "# Model parameters\n",
    "rf_n_estimators = 100\n",
    "rf_max_depth = 5\n",
    "lr_max_iter = 1000\n",
    "svm_kernel = \"rbf\"\n",
    "\n",
    "# Evaluation parameters\n",
    "scoring_metric = \"accuracy\"\n",
    "cv_folds = 5\n",
    "\n",
    "# Pipeline metadata\n",
    "pipeline_version = \"1.0.0\"\n",
    "pipeline_description = \"Iris classification pipeline with multiple models\"\n",
    "author = \"Pipeline Builder Extension\"\n",
    "\n",
    "print(\" Pipeline parameters configured:\")\n",
    "print(f\"    Dataset: {dataset_name}\")\n",
    "print(f\"    Target: {target_column}\")\n",
    "print(f\"    Test size: {test_size_param}\")\n",
    "print(f\"    Random state: {random_state_param}\")\n",
    "print(f\"    Version: {pipeline_version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efce581e-d454-493d-8572-65254f217b19",
   "metadata": {
    "tags": [
     "pipeline-metrics"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Generating pipeline metrics summary...\n",
      " Pipeline metrics computed:\n",
      "    Best model: SVM (0.9667)\n",
      "    Average accuracy: 0.9444 ± 0.0157\n",
      "    Total training time: 0.181s\n",
      "    Models trained: 3\n",
      "    Accuracy range: 0.0333\n",
      "\n",
      " Pipeline Quality Assessment:\n",
      "   Success threshold: 0.9\n",
      "   Pipeline passed:  YES\n",
      " Pipeline completed successfully with high accuracy!\n"
     ]
    }
   ],
   "source": [
    "# Pipeline Results and Metrics Summary\n",
    "print(\" Generating pipeline metrics summary...\")\n",
    "\n",
    "# Calculate overall pipeline metrics\n",
    "pipeline_success = True\n",
    "total_execution_time = sum(training_times.values())\n",
    "\n",
    "# Performance metrics\n",
    "avg_accuracy = np.mean([results['accuracy'] for results in evaluation_results.values()])\n",
    "std_accuracy = np.std([results['accuracy'] for results in evaluation_results.values()])\n",
    "\n",
    "# Model diversity\n",
    "accuracy_range = max(evaluation_results.values(), key=lambda x: x['accuracy'])['accuracy'] - \\\n",
    "                min(evaluation_results.values(), key=lambda x: x['accuracy'])['accuracy']\n",
    "\n",
    "# Final pipeline metrics\n",
    "pipeline_metrics = {\n",
    "    'pipeline_success': pipeline_success,\n",
    "    'best_model': best_model_name,\n",
    "    'best_accuracy': float(best_accuracy),\n",
    "    'average_accuracy': float(avg_accuracy),\n",
    "    'accuracy_std': float(std_accuracy),\n",
    "    'accuracy_range': float(accuracy_range),\n",
    "    'total_models': total_models_trained,\n",
    "    'total_training_time': float(total_execution_time),\n",
    "    'dataset_size': total_samples,\n",
    "    'test_samples': len(X_test),\n",
    "    'num_features': num_features,\n",
    "    'num_classes': num_classes\n",
    "}\n",
    "\n",
    "print(\" Pipeline metrics computed:\")\n",
    "print(f\"    Best model: {best_model_name} ({best_accuracy:.4f})\")\n",
    "print(f\"    Average accuracy: {avg_accuracy:.4f} ± {std_accuracy:.4f}\")\n",
    "print(f\"    Total training time: {total_execution_time:.3f}s\")\n",
    "print(f\"    Models trained: {total_models_trained}\")\n",
    "print(f\"    Accuracy range: {accuracy_range:.4f}\")\n",
    "\n",
    "# Success criteria\n",
    "success_threshold = 0.90\n",
    "pipeline_passed = best_accuracy >= success_threshold\n",
    "\n",
    "print(f\"\\n Pipeline Quality Assessment:\")\n",
    "print(f\"   Success threshold: {success_threshold}\")\n",
    "print(f\"   Pipeline passed: {' YES' if pipeline_passed else ' NO'}\")\n",
    "\n",
    "if pipeline_passed:\n",
    "    print(\" Pipeline completed successfully with high accuracy!\")\n",
    "else:\n",
    "    print(\" Pipeline completed but accuracy below threshold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f020d67-46a1-4bd5-9983-09f4d07a74c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
