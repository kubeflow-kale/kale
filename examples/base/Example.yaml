# PIPELINE DEFINITION
# Name: example
# Description: ML pipeline from annotated notebook
components:
  comp-data-loading:
    executorLabel: exec-data-loading
    outputDefinitions:
      artifacts:
        data_output:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
  comp-evaluation:
    executorLabel: exec-evaluation
    inputDefinitions:
      artifacts:
        X_test_input:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        model_input:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
        y_test_input:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
  comp-preprocessing:
    executorLabel: exec-preprocessing
    inputDefinitions:
      artifacts:
        data_input:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
    outputDefinitions:
      artifacts:
        X_test_output:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        X_train_output:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        y_test_output:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        y_train_output:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
  comp-training:
    executorLabel: exec-training
    inputDefinitions:
      artifacts:
        X_train_input:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        y_train_input:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
    outputDefinitions:
      artifacts:
        model_output:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
deploymentSpec:
  executors:
    exec-data-loading:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - data_loading
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.13.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'dill' 'pandas'\
          \ 'numpy' 'scikit-learn' 'joblib' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef data_loading(data_output: Output[Dataset]):\n    \"\"\"\n   \
          \ Data Loading component\n    Generated from notebook cell 0\n\n    Inputs:\
          \ []\n    Outputs: ['data']\n    \"\"\"\n    # === SHARED IMPORTS FROM NOTEBOOK\
          \ ===\n    import os\n    import pickle\n    from sklearn.linear_model import\
          \ LogisticRegression\n    from sklearn.metrics import accuracy_score\n \
          \   from sklearn.metrics import classification_report\n    from sklearn.model_selection\
          \ import train_test_split\n    import numpy\n    import pandas\n\n\n   \
          \ print(f\"Executing data_loading component...\")\n\n    # Simple marshal\
          \ implementation (embedded directly)\n    class SimpleMarshal:\n       \
          \ def __init__(self):\n            self._data_dir = '/tmp'\n\n        def\
          \ set_data_dir(self, path):\n            self._data_dir = path\n       \
          \     os.makedirs(path, exist_ok=True)\n            print(f\"Marshal data\
          \ dir: {path}\")\n\n        def save(self, obj, name):\n            import\
          \ joblib\n\n            # Choose appropriate serialization\n           \
          \ obj_type = str(type(obj))\n\n            if 'pandas' in obj_type:\n  \
          \              path = os.path.join(self._data_dir, f\"{name}.pdpkl\")\n\
          \                if hasattr(obj, 'to_pickle'):\n                    obj.to_pickle(path)\n\
          \                else:\n                    with open(path, 'wb') as f:\n\
          \                        pickle.dump(obj, f)\n            elif 'sklearn'\
          \ in obj_type:\n                path = os.path.join(self._data_dir, f\"\
          {name}.joblib\")\n                joblib.dump(obj, path)\n            else:\n\
          \                path = os.path.join(self._data_dir, f\"{name}.pkl\")\n\
          \                with open(path, 'wb') as f:\n                    pickle.dump(obj,\
          \ f)\n\n            print(f\"Saved {name} to {path}\")\n            return\
          \ path\n\n        def load(self, name):\n            # Use robust loading\
          \ technique - check for files with and without extensions\n            possible_files\
          \ = [\n                # First try files with extensions (from marshal.save)\n\
          \                os.path.join(self._data_dir, f\"{name}.pdpkl\"),\n    \
          \            os.path.join(self._data_dir, f\"{name}.joblib\"), \n      \
          \          os.path.join(self._data_dir, f\"{name}.pkl\"),\n            \
          \    # Then try the base name (from KFP artifact copy)\n               \
          \ os.path.join(self._data_dir, name)\n            ]\n\n            for file_path\
          \ in possible_files:\n                if os.path.exists(file_path):\n  \
          \                  print(f\"Loading {name} from {file_path}\")\n       \
          \             return self.robust_load(file_path, name)\n\n            available\
          \ = os.listdir(self._data_dir) if os.path.exists(self._data_dir) else []\n\
          \            raise FileNotFoundError(f\"Cannot find {name} in {self._data_dir}.\
          \ Available: {available}\")\n\n        def robust_load(self, file_path,\
          \ var_name):\n            \"\"\"Robust loading with multiple fallback methods\"\
          \"\"\n            try:\n                # Try joblib first (best for sklearn)\n\
          \                import joblib\n                result = joblib.load(file_path)\n\
          \                print(f\"Loaded {var_name} using joblib\")\n          \
          \      return result\n            except:\n                pass\n\n    \
          \        try:\n                # Try pickle with latin1 encoding (fixes\
          \ most issues)\n                with open(file_path, 'rb') as f:\n     \
          \               result = pickle.load(f, encoding='latin1')\n           \
          \     print(f\"Loaded {var_name} using pickle with latin1\")\n         \
          \       return result\n            except:\n                pass\n\n   \
          \         try:\n                # Try pandas for dataframes/series\n   \
          \             import pandas as pd\n                result = pd.read_pickle(file_path)\n\
          \                print(f\"Loaded {var_name} using pandas\")\n          \
          \      return result\n            except:\n                pass\n\n    \
          \        # Fallback to regular pickle\n            with open(file_path,\
          \ 'rb') as f:\n                result = pickle.load(f)\n            print(f\"\
          Loaded {var_name} using regular pickle\")\n            return result\n\n\
          \    # Create marshal instance\n    kale_marshal = SimpleMarshal()\n\n \
          \   # Set up marshal directory\n    import tempfile\n    marshal_dir = tempfile.mkdtemp(prefix='kale_marshal_')\n\
          \    kale_marshal.set_data_dir(marshal_dir)\n\n    # No input variables\
          \ to load\n\n    # Execute original cell code\n    print(\"Executing original\
          \ notebook code...\")\n    import pandas as pd\n    import numpy as np\n\
          \n    print(\" Creating simple dataset...\")\n\n    # Create a simple synthetic\
          \ dataset\n    np.random.seed(42)\n    n_samples = 100\n\n    # Features:\
          \ age, income\n    age = np.random.randint(18, 65, n_samples)\n    income\
          \ = age * 1000 + np.random.normal(0, 5000, n_samples)\n\n    # Target: can_buy_house\
          \ (1 if income > 50000, 0 otherwise)\n    target = (income > 50000).astype(int)\n\
          \n    # Create DataFrame\n    data = pd.DataFrame({\n        'age': age,\n\
          \        'income': income,\n        'can_buy_house': target\n    })\n\n\
          \    print(f\" Dataset created with {len(data)} samples\")\n    print(f\"\
          \ Features: age, income\")\n    print(f\" Target: can_buy_house\")\n   \
          \ print(\"\\nFirst 5 rows:\")\n    print(data.head())\n\n    dataset_size\
          \ = len(data)\n    feature_count = 2\n    print(\"Code execution completed\
          \ successfully\")\n\n    # Save output variables using Kale marshal system\n\
          \    # Save data\n    try:\n        if 'data' in locals() and data is not\
          \ None:\n            print(f'Saving data to data_output.path')\n       \
          \     print(f'Output artifact path: {data_output.path}')\n            #\
          \ Save using Kale marshal\n            marshal_file = kale_marshal.save(data,\
          \ 'data')\n            # Copy to KFP artifact location\n            import\
          \ shutil\n            os.makedirs(os.path.dirname(data_output.path), exist_ok=True)\n\
          \            shutil.copy2(marshal_file, data_output.path)\n            print(f'Successfully\
          \ saved data')\n        else:\n            print(f'Warning: data not found\
          \ in locals')\n    except Exception as e:\n        print(f'Error saving\
          \ data: {e}')\n        raise e\n\n\n    print(f\"data_loading component\
          \ completed successfully\")\n\n"
        image: python:3.9
    exec-evaluation:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - evaluation
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.13.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'dill' 'pandas'\
          \ 'numpy' 'scikit-learn' 'joblib' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef evaluation(model_input: Input[Model], y_test_input: Input[Dataset],\
          \ X_test_input: Input[Dataset]):\n    \"\"\"\n    Model Evaluation component\n\
          \    Generated from notebook cell 3\n\n    Inputs: ['model', 'y_test', 'X_test']\n\
          \    Outputs: []\n    \"\"\"\n    # === SHARED IMPORTS FROM NOTEBOOK ===\n\
          \    import os\n    import pickle\n    from sklearn.linear_model import\
          \ LogisticRegression\n    from sklearn.metrics import accuracy_score\n \
          \   from sklearn.metrics import classification_report\n    from sklearn.model_selection\
          \ import train_test_split\n    import numpy\n    import pandas\n\n\n   \
          \ print(f\"Executing evaluation component...\")\n\n    # Simple marshal\
          \ implementation (embedded directly)\n    class SimpleMarshal:\n       \
          \ def __init__(self):\n            self._data_dir = '/tmp'\n\n        def\
          \ set_data_dir(self, path):\n            self._data_dir = path\n       \
          \     os.makedirs(path, exist_ok=True)\n            print(f\"Marshal data\
          \ dir: {path}\")\n\n        def save(self, obj, name):\n            import\
          \ joblib\n\n            # Choose appropriate serialization\n           \
          \ obj_type = str(type(obj))\n\n            if 'pandas' in obj_type:\n  \
          \              path = os.path.join(self._data_dir, f\"{name}.pdpkl\")\n\
          \                if hasattr(obj, 'to_pickle'):\n                    obj.to_pickle(path)\n\
          \                else:\n                    with open(path, 'wb') as f:\n\
          \                        pickle.dump(obj, f)\n            elif 'sklearn'\
          \ in obj_type:\n                path = os.path.join(self._data_dir, f\"\
          {name}.joblib\")\n                joblib.dump(obj, path)\n            else:\n\
          \                path = os.path.join(self._data_dir, f\"{name}.pkl\")\n\
          \                with open(path, 'wb') as f:\n                    pickle.dump(obj,\
          \ f)\n\n            print(f\"Saved {name} to {path}\")\n            return\
          \ path\n\n        def load(self, name):\n            # Use robust loading\
          \ technique - check for files with and without extensions\n            possible_files\
          \ = [\n                # First try files with extensions (from marshal.save)\n\
          \                os.path.join(self._data_dir, f\"{name}.pdpkl\"),\n    \
          \            os.path.join(self._data_dir, f\"{name}.joblib\"), \n      \
          \          os.path.join(self._data_dir, f\"{name}.pkl\"),\n            \
          \    # Then try the base name (from KFP artifact copy)\n               \
          \ os.path.join(self._data_dir, name)\n            ]\n\n            for file_path\
          \ in possible_files:\n                if os.path.exists(file_path):\n  \
          \                  print(f\"Loading {name} from {file_path}\")\n       \
          \             return self.robust_load(file_path, name)\n\n            available\
          \ = os.listdir(self._data_dir) if os.path.exists(self._data_dir) else []\n\
          \            raise FileNotFoundError(f\"Cannot find {name} in {self._data_dir}.\
          \ Available: {available}\")\n\n        def robust_load(self, file_path,\
          \ var_name):\n            \"\"\"Robust loading with multiple fallback methods\"\
          \"\"\n            try:\n                # Try joblib first (best for sklearn)\n\
          \                import joblib\n                result = joblib.load(file_path)\n\
          \                print(f\"Loaded {var_name} using joblib\")\n          \
          \      return result\n            except:\n                pass\n\n    \
          \        try:\n                # Try pickle with latin1 encoding (fixes\
          \ most issues)\n                with open(file_path, 'rb') as f:\n     \
          \               result = pickle.load(f, encoding='latin1')\n           \
          \     print(f\"Loaded {var_name} using pickle with latin1\")\n         \
          \       return result\n            except:\n                pass\n\n   \
          \         try:\n                # Try pandas for dataframes/series\n   \
          \             import pandas as pd\n                result = pd.read_pickle(file_path)\n\
          \                print(f\"Loaded {var_name} using pandas\")\n          \
          \      return result\n            except:\n                pass\n\n    \
          \        # Fallback to regular pickle\n            with open(file_path,\
          \ 'rb') as f:\n                result = pickle.load(f)\n            print(f\"\
          Loaded {var_name} using regular pickle\")\n            return result\n\n\
          \    # Create marshal instance\n    kale_marshal = SimpleMarshal()\n\n \
          \   # Set up marshal directory\n    import tempfile\n    marshal_dir = tempfile.mkdtemp(prefix='kale_marshal_')\n\
          \    kale_marshal.set_data_dir(marshal_dir)\n\n    # Load input variables\
          \ using Kale marshal system\n    # Load model\n    try:\n        print(f'Loading\
          \ model from model_input.path')\n        print(f'Input artifact path: {model_input.path}')\n\
          \n        # Copy from KFP artifact to marshal dir\n        import shutil\n\
          \        marshal_file = os.path.join(marshal_dir, 'model')\n        shutil.copy2(model_input.path,\
          \ marshal_file)\n        # Load using Kale marshal with robust loading\n\
          \        model = kale_marshal.load('model')\n        print(f'Successfully\
          \ loaded model')\n    except Exception as e:\n        print(f'Error loading\
          \ model: {e}')\n        raise e\n\n    # Load y_test\n    try:\n       \
          \ print(f'Loading y_test from y_test_input.path')\n        print(f'Input\
          \ artifact path: {y_test_input.path}')\n\n        # Copy from KFP artifact\
          \ to marshal dir\n        import shutil\n        marshal_file = os.path.join(marshal_dir,\
          \ 'y_test')\n        shutil.copy2(y_test_input.path, marshal_file)\n   \
          \     # Load using Kale marshal with robust loading\n        y_test = kale_marshal.load('y_test')\n\
          \        print(f'Successfully loaded y_test')\n    except Exception as e:\n\
          \        print(f'Error loading y_test: {e}')\n        raise e\n\n    # Load\
          \ X_test\n    try:\n        print(f'Loading X_test from X_test_input.path')\n\
          \        print(f'Input artifact path: {X_test_input.path}')\n\n        #\
          \ Copy from KFP artifact to marshal dir\n        import shutil\n       \
          \ marshal_file = os.path.join(marshal_dir, 'X_test')\n        shutil.copy2(X_test_input.path,\
          \ marshal_file)\n        # Load using Kale marshal with robust loading\n\
          \        X_test = kale_marshal.load('X_test')\n        print(f'Successfully\
          \ loaded X_test')\n    except Exception as e:\n        print(f'Error loading\
          \ X_test: {e}')\n        raise e\n\n\n    # Execute original cell code\n\
          \    print(\"Executing original notebook code...\")\n    # Model evaluation\n\
          \    from sklearn.metrics import classification_report\n\n    print(\" Evaluating\
          \ model...\")\n\n    # Make predictions\n    test_predictions = model.predict(X_test)\n\
          \    test_accuracy = accuracy_score(y_test, test_predictions)\n\n    print(f\"\
          \ Test accuracy: {test_accuracy:.3f}\")\n\n    # Detailed evaluation\n \
          \   print(\"\\n Classification Report:\")\n    print(classification_report(y_test,\
          \ test_predictions))\n\n    # Simple predictions on new data\n    print(\"\
          \\n Sample predictions:\")\n    sample_data = [[25, 30000], [45, 80000],\
          \ [35, 60000]]\n    sample_predictions = model.predict(sample_data)\n\n\
          \    for i, (age, income) in enumerate(sample_data):\n        prediction\
          \ = \"Yes\" if sample_predictions[i] == 1 else \"No\"\n        print(f\"\
          \   Age {age}, Income ${income:,} \u2192 Can buy house: {prediction}\")\n\
          \n    # Final metrics\n    final_accuracy = test_accuracy\n    total_correct\
          \ = int(test_accuracy * len(y_test))\n    model_performance = \"Good\" if\
          \ test_accuracy > 0.8 else \"Fair\" if test_accuracy > 0.6 else \"Poor\"\
          \n\n    print(f\"\\n Evaluation completed!\")\n    print(f\" Final accuracy:\
          \ {final_accuracy:.3f}\")\n    print(f\" Correct predictions: {total_correct}/{len(y_test)}\"\
          )\n    print(f\" Model performance: {model_performance}\")\n    print(\"\
          Code execution completed successfully\")\n\n    # No output variables to\
          \ save\n\n    print(f\"evaluation component completed successfully\")\n\n"
        image: python:3.9
    exec-preprocessing:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - preprocessing
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.13.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'dill' 'pandas'\
          \ 'numpy' 'scikit-learn' 'joblib' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef preprocessing(data_input: Input[Dataset], X_train_output: Output[Dataset],\
          \ y_train_output: Output[Dataset], y_test_output: Output[Dataset], X_test_output:\
          \ Output[Dataset]):\n    \"\"\"\n    Data Preprocessing component\n    Generated\
          \ from notebook cell 1\n\n    Inputs: ['data']\n    Outputs: ['X_train',\
          \ 'y_train', 'y_test', 'X_test']\n    \"\"\"\n    # === SHARED IMPORTS FROM\
          \ NOTEBOOK ===\n    import os\n    import pickle\n    from sklearn.linear_model\
          \ import LogisticRegression\n    from sklearn.metrics import accuracy_score\n\
          \    from sklearn.metrics import classification_report\n    from sklearn.model_selection\
          \ import train_test_split\n    import numpy\n    import pandas\n\n\n   \
          \ print(f\"Executing preprocessing component...\")\n\n    # Simple marshal\
          \ implementation (embedded directly)\n    class SimpleMarshal:\n       \
          \ def __init__(self):\n            self._data_dir = '/tmp'\n\n        def\
          \ set_data_dir(self, path):\n            self._data_dir = path\n       \
          \     os.makedirs(path, exist_ok=True)\n            print(f\"Marshal data\
          \ dir: {path}\")\n\n        def save(self, obj, name):\n            import\
          \ joblib\n\n            # Choose appropriate serialization\n           \
          \ obj_type = str(type(obj))\n\n            if 'pandas' in obj_type:\n  \
          \              path = os.path.join(self._data_dir, f\"{name}.pdpkl\")\n\
          \                if hasattr(obj, 'to_pickle'):\n                    obj.to_pickle(path)\n\
          \                else:\n                    with open(path, 'wb') as f:\n\
          \                        pickle.dump(obj, f)\n            elif 'sklearn'\
          \ in obj_type:\n                path = os.path.join(self._data_dir, f\"\
          {name}.joblib\")\n                joblib.dump(obj, path)\n            else:\n\
          \                path = os.path.join(self._data_dir, f\"{name}.pkl\")\n\
          \                with open(path, 'wb') as f:\n                    pickle.dump(obj,\
          \ f)\n\n            print(f\"Saved {name} to {path}\")\n            return\
          \ path\n\n        def load(self, name):\n            # Use robust loading\
          \ technique - check for files with and without extensions\n            possible_files\
          \ = [\n                # First try files with extensions (from marshal.save)\n\
          \                os.path.join(self._data_dir, f\"{name}.pdpkl\"),\n    \
          \            os.path.join(self._data_dir, f\"{name}.joblib\"), \n      \
          \          os.path.join(self._data_dir, f\"{name}.pkl\"),\n            \
          \    # Then try the base name (from KFP artifact copy)\n               \
          \ os.path.join(self._data_dir, name)\n            ]\n\n            for file_path\
          \ in possible_files:\n                if os.path.exists(file_path):\n  \
          \                  print(f\"Loading {name} from {file_path}\")\n       \
          \             return self.robust_load(file_path, name)\n\n            available\
          \ = os.listdir(self._data_dir) if os.path.exists(self._data_dir) else []\n\
          \            raise FileNotFoundError(f\"Cannot find {name} in {self._data_dir}.\
          \ Available: {available}\")\n\n        def robust_load(self, file_path,\
          \ var_name):\n            \"\"\"Robust loading with multiple fallback methods\"\
          \"\"\n            try:\n                # Try joblib first (best for sklearn)\n\
          \                import joblib\n                result = joblib.load(file_path)\n\
          \                print(f\"Loaded {var_name} using joblib\")\n          \
          \      return result\n            except:\n                pass\n\n    \
          \        try:\n                # Try pickle with latin1 encoding (fixes\
          \ most issues)\n                with open(file_path, 'rb') as f:\n     \
          \               result = pickle.load(f, encoding='latin1')\n           \
          \     print(f\"Loaded {var_name} using pickle with latin1\")\n         \
          \       return result\n            except:\n                pass\n\n   \
          \         try:\n                # Try pandas for dataframes/series\n   \
          \             import pandas as pd\n                result = pd.read_pickle(file_path)\n\
          \                print(f\"Loaded {var_name} using pandas\")\n          \
          \      return result\n            except:\n                pass\n\n    \
          \        # Fallback to regular pickle\n            with open(file_path,\
          \ 'rb') as f:\n                result = pickle.load(f)\n            print(f\"\
          Loaded {var_name} using regular pickle\")\n            return result\n\n\
          \    # Create marshal instance\n    kale_marshal = SimpleMarshal()\n\n \
          \   # Set up marshal directory\n    import tempfile\n    marshal_dir = tempfile.mkdtemp(prefix='kale_marshal_')\n\
          \    kale_marshal.set_data_dir(marshal_dir)\n\n    # Load input variables\
          \ using Kale marshal system\n    # Load data\n    try:\n        print(f'Loading\
          \ data from data_input.path')\n        print(f'Input artifact path: {data_input.path}')\n\
          \n        # Copy from KFP artifact to marshal dir\n        import shutil\n\
          \        marshal_file = os.path.join(marshal_dir, 'data')\n        shutil.copy2(data_input.path,\
          \ marshal_file)\n        # Load using Kale marshal with robust loading\n\
          \        data = kale_marshal.load('data')\n        print(f'Successfully\
          \ loaded data')\n    except Exception as e:\n        print(f'Error loading\
          \ data: {e}')\n        raise e\n\n\n    # Execute original cell code\n \
          \   print(\"Executing original notebook code...\")\n    # Data preparation\n\
          \    from sklearn.model_selection import train_test_split\n\n    print(\"\
          \ Preparing data for training...\")\n\n    # Separate features and target\n\
          \    X = data[['age', 'income']]\n    y = data['can_buy_house']\n\n    print(f\"\
          \ Features shape: {X.shape}\")\n    print(f\" Target shape: {y.shape}\"\
          )\n\n    # Split data\n    X_train, X_test, y_train, y_test = train_test_split(\n\
          \        X, y, test_size=0.3, random_state=42\n    )\n\n    print(f\" Training\
          \ samples: {len(X_train)}\")\n    print(f\" Test samples: {len(X_test)}\"\
          )\n\n    # Basic statistics\n    print(f\"\\n Training data stats:\")\n\
          \    print(f\"   Average age: {X_train['age'].mean():.1f}\")\n    print(f\"\
          \   Average income: ${X_train['income'].mean():.0f}\")\n    print(f\"  \
          \ Positive cases: {y_train.sum()}/{len(y_train)}\")\n\n    train_samples\
          \ = len(X_train)\n    test_samples = len(X_test)\n\n    print(\" Data preparation\
          \ completed!\")\n    print(\"Code execution completed successfully\")\n\n\
          \    # Save output variables using Kale marshal system\n    # Save X_train\n\
          \    try:\n        if 'X_train' in locals() and X_train is not None:\n \
          \           print(f'Saving X_train to X_train_output.path')\n          \
          \  print(f'Output artifact path: {X_train_output.path}')\n            #\
          \ Save using Kale marshal\n            marshal_file = kale_marshal.save(X_train,\
          \ 'X_train')\n            # Copy to KFP artifact location\n            import\
          \ shutil\n            os.makedirs(os.path.dirname(X_train_output.path),\
          \ exist_ok=True)\n            shutil.copy2(marshal_file, X_train_output.path)\n\
          \            print(f'Successfully saved X_train')\n        else:\n     \
          \       print(f'Warning: X_train not found in locals')\n    except Exception\
          \ as e:\n        print(f'Error saving X_train: {e}')\n        raise e\n\n\
          \    # Save y_train\n    try:\n        if 'y_train' in locals() and y_train\
          \ is not None:\n            print(f'Saving y_train to y_train_output.path')\n\
          \            print(f'Output artifact path: {y_train_output.path}')\n   \
          \         # Save using Kale marshal\n            marshal_file = kale_marshal.save(y_train,\
          \ 'y_train')\n            # Copy to KFP artifact location\n            import\
          \ shutil\n            os.makedirs(os.path.dirname(y_train_output.path),\
          \ exist_ok=True)\n            shutil.copy2(marshal_file, y_train_output.path)\n\
          \            print(f'Successfully saved y_train')\n        else:\n     \
          \       print(f'Warning: y_train not found in locals')\n    except Exception\
          \ as e:\n        print(f'Error saving y_train: {e}')\n        raise e\n\n\
          \    # Save y_test\n    try:\n        if 'y_test' in locals() and y_test\
          \ is not None:\n            print(f'Saving y_test to y_test_output.path')\n\
          \            print(f'Output artifact path: {y_test_output.path}')\n    \
          \        # Save using Kale marshal\n            marshal_file = kale_marshal.save(y_test,\
          \ 'y_test')\n            # Copy to KFP artifact location\n            import\
          \ shutil\n            os.makedirs(os.path.dirname(y_test_output.path), exist_ok=True)\n\
          \            shutil.copy2(marshal_file, y_test_output.path)\n          \
          \  print(f'Successfully saved y_test')\n        else:\n            print(f'Warning:\
          \ y_test not found in locals')\n    except Exception as e:\n        print(f'Error\
          \ saving y_test: {e}')\n        raise e\n\n    # Save X_test\n    try:\n\
          \        if 'X_test' in locals() and X_test is not None:\n            print(f'Saving\
          \ X_test to X_test_output.path')\n            print(f'Output artifact path:\
          \ {X_test_output.path}')\n            # Save using Kale marshal\n      \
          \      marshal_file = kale_marshal.save(X_test, 'X_test')\n            #\
          \ Copy to KFP artifact location\n            import shutil\n           \
          \ os.makedirs(os.path.dirname(X_test_output.path), exist_ok=True)\n    \
          \        shutil.copy2(marshal_file, X_test_output.path)\n            print(f'Successfully\
          \ saved X_test')\n        else:\n            print(f'Warning: X_test not\
          \ found in locals')\n    except Exception as e:\n        print(f'Error saving\
          \ X_test: {e}')\n        raise e\n\n\n    print(f\"preprocessing component\
          \ completed successfully\")\n\n"
        image: python:3.9
    exec-training:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - training
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.13.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'dill' 'pandas'\
          \ 'numpy' 'scikit-learn' 'joblib' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef training(X_train_input: Input[Dataset], y_train_input: Input[Dataset],\
          \ model_output: Output[Model]):\n    \"\"\"\n    Model Training component\n\
          \    Generated from notebook cell 2\n\n    Inputs: ['X_train', 'y_train']\n\
          \    Outputs: ['model']\n    \"\"\"\n    # === SHARED IMPORTS FROM NOTEBOOK\
          \ ===\n    import os\n    import pickle\n    from sklearn.linear_model import\
          \ LogisticRegression\n    from sklearn.metrics import accuracy_score\n \
          \   from sklearn.metrics import classification_report\n    from sklearn.model_selection\
          \ import train_test_split\n    import numpy\n    import pandas\n\n\n   \
          \ print(f\"Executing training component...\")\n\n    # Simple marshal implementation\
          \ (embedded directly)\n    class SimpleMarshal:\n        def __init__(self):\n\
          \            self._data_dir = '/tmp'\n\n        def set_data_dir(self, path):\n\
          \            self._data_dir = path\n            os.makedirs(path, exist_ok=True)\n\
          \            print(f\"Marshal data dir: {path}\")\n\n        def save(self,\
          \ obj, name):\n            import joblib\n\n            # Choose appropriate\
          \ serialization\n            obj_type = str(type(obj))\n\n            if\
          \ 'pandas' in obj_type:\n                path = os.path.join(self._data_dir,\
          \ f\"{name}.pdpkl\")\n                if hasattr(obj, 'to_pickle'):\n  \
          \                  obj.to_pickle(path)\n                else:\n        \
          \            with open(path, 'wb') as f:\n                        pickle.dump(obj,\
          \ f)\n            elif 'sklearn' in obj_type:\n                path = os.path.join(self._data_dir,\
          \ f\"{name}.joblib\")\n                joblib.dump(obj, path)\n        \
          \    else:\n                path = os.path.join(self._data_dir, f\"{name}.pkl\"\
          )\n                with open(path, 'wb') as f:\n                    pickle.dump(obj,\
          \ f)\n\n            print(f\"Saved {name} to {path}\")\n            return\
          \ path\n\n        def load(self, name):\n            # Use robust loading\
          \ technique - check for files with and without extensions\n            possible_files\
          \ = [\n                # First try files with extensions (from marshal.save)\n\
          \                os.path.join(self._data_dir, f\"{name}.pdpkl\"),\n    \
          \            os.path.join(self._data_dir, f\"{name}.joblib\"), \n      \
          \          os.path.join(self._data_dir, f\"{name}.pkl\"),\n            \
          \    # Then try the base name (from KFP artifact copy)\n               \
          \ os.path.join(self._data_dir, name)\n            ]\n\n            for file_path\
          \ in possible_files:\n                if os.path.exists(file_path):\n  \
          \                  print(f\"Loading {name} from {file_path}\")\n       \
          \             return self.robust_load(file_path, name)\n\n            available\
          \ = os.listdir(self._data_dir) if os.path.exists(self._data_dir) else []\n\
          \            raise FileNotFoundError(f\"Cannot find {name} in {self._data_dir}.\
          \ Available: {available}\")\n\n        def robust_load(self, file_path,\
          \ var_name):\n            \"\"\"Robust loading with multiple fallback methods\"\
          \"\"\n            try:\n                # Try joblib first (best for sklearn)\n\
          \                import joblib\n                result = joblib.load(file_path)\n\
          \                print(f\"Loaded {var_name} using joblib\")\n          \
          \      return result\n            except:\n                pass\n\n    \
          \        try:\n                # Try pickle with latin1 encoding (fixes\
          \ most issues)\n                with open(file_path, 'rb') as f:\n     \
          \               result = pickle.load(f, encoding='latin1')\n           \
          \     print(f\"Loaded {var_name} using pickle with latin1\")\n         \
          \       return result\n            except:\n                pass\n\n   \
          \         try:\n                # Try pandas for dataframes/series\n   \
          \             import pandas as pd\n                result = pd.read_pickle(file_path)\n\
          \                print(f\"Loaded {var_name} using pandas\")\n          \
          \      return result\n            except:\n                pass\n\n    \
          \        # Fallback to regular pickle\n            with open(file_path,\
          \ 'rb') as f:\n                result = pickle.load(f)\n            print(f\"\
          Loaded {var_name} using regular pickle\")\n            return result\n\n\
          \    # Create marshal instance\n    kale_marshal = SimpleMarshal()\n\n \
          \   # Set up marshal directory\n    import tempfile\n    marshal_dir = tempfile.mkdtemp(prefix='kale_marshal_')\n\
          \    kale_marshal.set_data_dir(marshal_dir)\n\n    # Load input variables\
          \ using Kale marshal system\n    # Load X_train\n    try:\n        print(f'Loading\
          \ X_train from X_train_input.path')\n        print(f'Input artifact path:\
          \ {X_train_input.path}')\n\n        # Copy from KFP artifact to marshal\
          \ dir\n        import shutil\n        marshal_file = os.path.join(marshal_dir,\
          \ 'X_train')\n        shutil.copy2(X_train_input.path, marshal_file)\n \
          \       # Load using Kale marshal with robust loading\n        X_train =\
          \ kale_marshal.load('X_train')\n        print(f'Successfully loaded X_train')\n\
          \    except Exception as e:\n        print(f'Error loading X_train: {e}')\n\
          \        raise e\n\n    # Load y_train\n    try:\n        print(f'Loading\
          \ y_train from y_train_input.path')\n        print(f'Input artifact path:\
          \ {y_train_input.path}')\n\n        # Copy from KFP artifact to marshal\
          \ dir\n        import shutil\n        marshal_file = os.path.join(marshal_dir,\
          \ 'y_train')\n        shutil.copy2(y_train_input.path, marshal_file)\n \
          \       # Load using Kale marshal with robust loading\n        y_train =\
          \ kale_marshal.load('y_train')\n        print(f'Successfully loaded y_train')\n\
          \    except Exception as e:\n        print(f'Error loading y_train: {e}')\n\
          \        raise e\n\n\n    # Execute original cell code\n    print(\"Executing\
          \ original notebook code...\")\n    # Model training\n    from sklearn.linear_model\
          \ import LogisticRegression\n    from sklearn.metrics import accuracy_score\n\
          \n    print(\" Training model...\")\n\n    # Create and train model\n  \
          \  model = LogisticRegression(random_state=42)\n    model.fit(X_train, y_train)\n\
          \n    print(\" Model training completed!\")\n\n    # Check training accuracy\n\
          \    train_predictions = model.predict(X_train)\n    train_accuracy = accuracy_score(y_train,\
          \ train_predictions)\n\n    print(f\" Training accuracy: {train_accuracy:.3f}\"\
          )\n\n    # Model info\n    model_type = \"LogisticRegression\"\n    coefficients\
          \ = model.coef_[0]\n\n    print(f\" Model coefficients:\")\n    print(f\"\
          \   Age coefficient: {coefficients[0]:.4f}\")\n    print(f\"   Income coefficient:\
          \ {coefficients[1]:.6f}\")\n\n    training_accuracy = train_accuracy\n \
          \   print(\"Code execution completed successfully\")\n\n    # Save output\
          \ variables using Kale marshal system\n    # Save model\n    try:\n    \
          \    if 'model' in locals() and model is not None:\n            print(f'Saving\
          \ model to model_output.path')\n            print(f'Output artifact path:\
          \ {model_output.path}')\n            # Save using Kale marshal\n       \
          \     marshal_file = kale_marshal.save(model, 'model')\n            # Copy\
          \ to KFP artifact location\n            import shutil\n            os.makedirs(os.path.dirname(model_output.path),\
          \ exist_ok=True)\n            shutil.copy2(marshal_file, model_output.path)\n\
          \            print(f'Successfully saved model')\n        else:\n       \
          \     print(f'Warning: model not found in locals')\n    except Exception\
          \ as e:\n        print(f'Error saving model: {e}')\n        raise e\n\n\n\
          \    print(f\"training component completed successfully\")\n\n"
        image: python:3.9
pipelineInfo:
  description: ML pipeline from annotated notebook
  name: example
root:
  dag:
    tasks:
      data-loading:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-data-loading
        taskInfo:
          name: data-loading
      evaluation:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-evaluation
        dependentTasks:
        - preprocessing
        - training
        inputs:
          artifacts:
            X_test_input:
              taskOutputArtifact:
                outputArtifactKey: X_test_output
                producerTask: preprocessing
            model_input:
              taskOutputArtifact:
                outputArtifactKey: model_output
                producerTask: training
            y_test_input:
              taskOutputArtifact:
                outputArtifactKey: y_test_output
                producerTask: preprocessing
        taskInfo:
          name: evaluation
      preprocessing:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-preprocessing
        dependentTasks:
        - data-loading
        inputs:
          artifacts:
            data_input:
              taskOutputArtifact:
                outputArtifactKey: data_output
                producerTask: data-loading
        taskInfo:
          name: preprocessing
      training:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-training
        dependentTasks:
        - preprocessing
        inputs:
          artifacts:
            X_train_input:
              taskOutputArtifact:
                outputArtifactKey: X_train_output
                producerTask: preprocessing
            y_train_input:
              taskOutputArtifact:
                outputArtifactKey: y_train_output
                producerTask: preprocessing
        taskInfo:
          name: training
schemaVersion: 2.1.0
sdkVersion: kfp-2.13.0
