"""
Generated Kubeflow Pipelines v2 DSL from Annotated Jupyter Notebook
Auto-generated code - modify as needed for your specific requirements

Generated by: Pipeline Builder Extension
Source: Annotated Jupyter Notebook
Target: KFP v2 DSL Python
"""

from kfp import dsl, compiler
from kfp.dsl import Input, Output, Model, Dataset, Metrics, Artifact, component, pipeline
from typing import NamedTuple, Dict, List, Any
import os

# =============================================================================
# GENERATED COMPONENTS FROM NOTEBOOK CELLS
# =============================================================================

@dsl.component(
    base_image='python:3.9',
    packages_to_install=['numpy', 'pandas', 'scikit-learn']
)
def data_loading() -> str:
    """
    Pipeline step: step:data-loading
    Generated from notebook cell 2
    Original tags: step:data-loading
    """
    # Imports
    import os
    import sys
    import json
    import pickle
    from pathlib import Path
    
    print("Executing data_loading component...")
    print("Original cell content from notebook cell 2")
    
    # Original cell code
    print("Hello world!1")
    
    print("data_loading component execution completed")
    
    # Return results - Fixed version
    result_vars = [k for k in locals().keys() if not k.startswith('_') and not callable(locals().get(k, None))]
    if result_vars:
        summary = f"Executed successfully. Created variables: {', '.join(result_vars[:5])}"
        if len(result_vars) > 5:
            summary += f" and {len(result_vars) - 5} more"
        return summary
    else:
        return "data_loading completed successfully"

@dsl.component(
    base_image='python:3.9',
    packages_to_install=['numpy', 'pandas', 'scikit-learn']
)
def preprocessing() -> str:
    """
    Pipeline step: step:preprocessing
    Generated from notebook cell 3
    Original tags: step:preprocessing
    """
    # Imports
    import os
    import sys
    import json
    import pickle
    from pathlib import Path
    
    print("Executing preprocessing component...")
    print("Original cell content from notebook cell 3")
    
    # Original cell code
    print("Hello world!2")
    
    print("preprocessing component execution completed")
    
    # Return results - Fixed version
    result_vars = [k for k in locals().keys() if not k.startswith('_') and not callable(locals().get(k, None))]
    if result_vars:
        summary = f"Executed successfully. Created variables: {', '.join(result_vars[:5])}"
        if len(result_vars) > 5:
            summary += f" and {len(result_vars) - 5} more"
        return summary
    else:
        return "preprocessing completed successfully"

@dsl.component(
    base_image='python:3.9',
    packages_to_install=['numpy', 'pandas', 'scikit-learn']
)
def pipeline_metrics_4() -> NamedTuple('Metrics', [('metrics', dict)]):
    """
    Pipeline metrics calculation
    Generated from notebook cell 4
    """
    import json
    from typing import NamedTuple
    from collections import namedtuple
    
    print("Computing metrics from cell 4...")
    
    # Original cell code
    print("Hello world!3")
    
    # Extract metrics from local variables - Fixed version
    metrics = {}
    for k, v in locals().items():
        if (not k.startswith('_') and 
            not callable(v) and 
            isinstance(v, (int, float, str, bool)) and 
            k not in ['json', 'NamedTuple', 'namedtuple', 'print']):
            metrics[k] = v
    
    # Add some default metrics since the cell just prints
    metrics['execution_status'] = 'completed'
    metrics['cell_number'] = 4
    metrics['message'] = 'Hello world!3'
    
    print(f"Computed metrics: {list(metrics.keys())}")
    print("Metrics computation completed")
    
    Metrics = namedtuple('Metrics', ['metrics'])
    return Metrics(metrics)

# =============================================================================
# PIPELINE DEFINITION
# =============================================================================

@dsl.pipeline(
    name='Untitled',
    description='Generated from annotated notebook'
)
def Untitled_pipeline():
    """
    Generated pipeline from annotated notebook cells
    
    Pipeline steps:
    - Step 1: data_loading
    - Step 2: preprocessing
    - Step 3: pipeline_metrics_4
    """
    data_loading_task = data_loading()
    preprocessing_task = preprocessing().after(data_loading_task)
    pipeline_metrics_4_task = pipeline_metrics_4().after(preprocessing_task)

# =============================================================================
# COMPILATION AND EXECUTION
# =============================================================================

def compile_pipeline(output_path: str = None) -> str:
    """
    Compile the pipeline to a YAML file
    """
    if output_path is None:
        output_path = 'Untitled_kfp_pipeline.yaml'
    
    compiler.Compiler().compile(
        pipeline_func=Untitled_pipeline,
        package_path=output_path
    )
    
    print("Pipeline compiled successfully!")
    print(" Generated file: " + output_path)
    return output_path


def test_components_locally():
    """
    Test components locally without KFP
    """
    print("Testing components locally...")
    
    try:
        print("\nTesting data_loading...")
        result1 = data_loading.python_func() if hasattr(data_loading, 'python_func') else data_loading()
        print(f"Result: {result1}")
        
        print("\nTesting preprocessing...")
        result2 = preprocessing.python_func() if hasattr(preprocessing, 'python_func') else preprocessing()
        print(f"Result: {result2}")
        
        print("\nTesting pipeline_metrics_4...")
        result3 = pipeline_metrics_4.python_func() if hasattr(pipeline_metrics_4, 'python_func') else pipeline_metrics_4()
        print(f"Result: {result3}")
        
        print("\nAll components tested successfully!")
        print("Summary:")
        print(f"   Data Loading: {result1}")
        print(f"   Preprocessing: {result2}")
        print(f"   Metrics: {result3}")
        
        return True
        
    except Exception as e:
        print(f"Component test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def run_pipeline_local():
    """
    Run the pipeline locally for testing
    """
    print("Running pipeline locally...")
    
    try:
        # Try KFP local first
        import kfp.local
        kfp.local.init()
        print("KFP local environment initialized")
        Untitled_pipeline()
        print("Local pipeline execution completed!")
        
    except ImportError:
        print("KFP local not available, testing components individually...")
        return test_components_locally()
        
    except Exception as e:
        print(f"KFP local failed ({e}), testing components individually...")
        return test_components_locally()


def main():
    """Main execution function"""
    import argparse
    import sys
    
    parser = argparse.ArgumentParser(description="Generated KFP Pipeline")
    parser.add_argument("--compile", action="store_true", default=True, 
                       help="Compile pipeline to YAML (default)")
    parser.add_argument("--run-local", action="store_true", 
                       help="Run pipeline locally for testing")
    parser.add_argument("--test-components", action="store_true",
                       help="Test individual components")
    parser.add_argument("--kfp-host", type=str, 
                       help="KFP cluster host URL for submission")
    parser.add_argument("--experiment", type=str, default="default",
                       help="KFP experiment name")
    parser.add_argument("--output", "-o", type=str,
                       help="Output path for compiled YAML")
    
    # If no arguments provided, just compile by default
    if len(sys.argv) == 1:
        print("Compiling pipeline (default action)...")
        compile_pipeline()
        return
    
    args = parser.parse_args()
    
    try:
        if args.test_components:
            test_components_locally()
            return
            
        if args.run_local:
            print("Running pipeline locally...")
            run_pipeline_local()
            return
        
        if args.compile and not args.kfp_host:
            # Default: compile to YAML
            print("Compiling pipeline to YAML...")
            output_file = compile_pipeline(args.output)
            print("Pipeline compiled to: " + output_file)
            print("Next steps:")
            print("   - Test components: python " + sys.argv[0] + " --test-components")
            print("   - Test locally: python " + sys.argv[0] + " --run-local")
            print("   - Upload YAML manually to KFP UI")
        
        if args.kfp_host:
            print(f"Submitting pipeline to KFP cluster: " + args.kfp_host)
            
            # # Prepare submission arguments
            # submission_args = {}
            # if args.experiment:
            #     submission_args['experiment_name'] = args.experiment
            # if args.run_name:
            #     submission_args['run_name'] = args.run_name
            
            # run_id = submit_pipeline(
            #     host=args.kfp_host,
            #     **submission_args
            # )
            # print(f"âœ… Pipeline submitted with run ID: " + run_id)

            import kfp
            client = kfp.Client(host=args.kfp_host)
            
            # Submit without any arguments since your pipeline doesn't take parameters
            run_result = client.create_run_from_pipeline_func(
                pipeline_func=Untitled_pipeline,
                arguments={},  # Empty - no pipeline parameters
                run_name="untitled-pipeline-run",
                experiment_name=args.experiment
            )
            
            print(f"Pipeline submitted successfully!")
            print(f"Run ID: {run_result.run_id}")
            print(f"View run: {args.kfp_host}/#/runs/details/{run_result.run_id}")
    
    except Exception as e:
        print("Error: " + str(e))
        sys.exit(1)


if __name__ == "__main__":
    main()